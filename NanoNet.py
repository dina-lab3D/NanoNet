import argparse
import os
import sys
import numpy as np
import logging
import subprocess
from Bio import SeqIO
from Bio.PDB import Polypeptide
from timeit import default_timer as timer
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}
import tensorflow as tf


HEADER = "HEADER    IMMUNE SYSTEM - NANOBODY {}                          \nTITLE     COMPUTATIONAL MODELING      \nREMARK 777 MODEL GENERATED BY NANONET \n"
ATOM_LINE = "ATOM{}{}  CA  {} H{}{}{}{:.3f}{}{:.3f}{}{:.3f}  1.00{}{:.2f}           C\n"
END_LINE = "END\n"

NB_MAX_LENGTH = 140
FEATURE_NUM = 22
AA_DICT = {"A": 0, "C": 1, "D": 2, "E": 3, "F": 4, "G": 5, "H": 6, "I": 7, "K": 8, "L": 9, "M": 10, "N": 11, "P": 12,
           "Q": 13, "R": 14, "S": 15, "T": 16, "W": 17, "Y": 18, "V": 19, "-": 21, "X": 20}


def pad_seq(seq):
    """
    pads a Nb sequence with "-" to match the length required for NanoNet (NB_MAX_LENGTH)
    :param seq: Nb sequence (String) with len =< 140
    :return: Nb sequence (String) with len == 140 (with insertions)
    """
    seq_len = len(seq)
    up_pad = (NB_MAX_LENGTH - seq_len) // 2
    down_pad = NB_MAX_LENGTH - up_pad - seq_len

    # pad the sequence with '-'
    seq = up_pad * "-" + seq + down_pad * "-"
    return seq


def seq_iterator(fasta_file_path):
    """
    iterates over a fasta file
    :param fasta_file_path: path to fasta file
    :return:yields sequence, name
    """
    for seq_record in SeqIO.parse(fasta_file_path, "fasta"):
        seq = str(seq_record.seq)
        name = str(seq_record.name)
        yield seq, name


def generate_input(seq):
    """
    receives a Nb sequence and returns its  sequence in a one-hot encoding matrix (each row is an aa in the sequence, and
    each column represents a different aa out of the 20 aa + 2 special columns).
    :param seq: sequence (string)
    :return: numpy array of size (NB_MAX_LENGTH * FEATURE_NUM)
    """

    if "X" in seq:
        print("Warning, sequence: {}, has unknown aa".format(seq))

    # pad the sequence with '-'
    seq = pad_seq(seq)

    # turn in to one-hot encoding matrix
    seq_matrix = np.zeros((NB_MAX_LENGTH, FEATURE_NUM))
    for i in range(NB_MAX_LENGTH):
        seq_matrix[i][AA_DICT[seq[i]]] = 1

    return seq_matrix


def matrix_to_pdb(pdb_file, seq, coord_matrix, pdb_name):
    """
    writes coord_matrix into pdb_file with PDB format
    :param pdb_file: file to write into
    :param seq: sequence of the Nb
    :param coord_matrix: ca coordinates matrix (generated by NanoNet)
    :return: None
    """
    seq = pad_seq(seq)
    i = 1
    for aa in range(len(seq)):
        if seq[aa] != "-":
            first_space = (7 - len(str(i))) * " "
            second_space = (4 - len(str(i))) * " "
            third_space = (12 - len("{:.3f}".format(coord_matrix[aa][0]))) * " "
            forth_space = (8 - len("{:.3f}".format(coord_matrix[aa][1]))) * " "
            fifth_space = (8 - len("{:.3f}".format(coord_matrix[aa][2]))) * " "
            b_factor = 0.00
            sixth_space = (6 - len("{:.2f}".format(b_factor))) * " "
            if seq[aa] == "X":
                three_letter = "UNK"
            else:
                three_letter = Polypeptide.one_to_three(seq[aa])
            pdb_file.write(ATOM_LINE.format(first_space, i, three_letter, second_space, i, third_space, coord_matrix[aa][0],forth_space, coord_matrix[aa][1],fifth_space, coord_matrix[aa][2], sixth_space, b_factor))
            i += 1
    pdb_file.write(END_LINE)


def run_nanonet(fasta_path, nanonet_path, single_file, output_dir, reconstruct, run_pulchra):
    
    # make input for NanoNet
    sequences = []
    names = []
    for sequence, name in seq_iterator(fasta_path):
        sequences.append(sequence)
        names.append(name)

    input_matrix  = np.zeros((len(sequences), NB_MAX_LENGTH, FEATURE_NUM))
    for i in range(len(input_matrix)):
        input_matrix[i] = generate_input(sequences[i])

    # load model
    logging.getLogger('tensorflow').disabled = True
    nanonet = tf.keras.models.load_model(nanonet_path, compile=False)

    # predict Nb ca coordinates
    ca_coords = nanonet.predict(np.array(input_matrix))

    # change to output directory
    if not os.path.exists(output_dir):
        os.mkdir(output_dir)

    # create one ca pdb file
    if single_file:
        ca_file_name = "nanonet_ca.pdb"
        ca_file_path = os.path.join(output_dir, ca_file_name)
        with open(ca_file_path, "w") as ca_file:
            ca_file.write(HEADER.format(""))
            for coords, sequence, name in zip(ca_coords, sequences, names):
                ca_file.write("MODEL {}\n".format(name))
                matrix_to_pdb(ca_file, sequence, coords, name)
                ca_file.write("ENDMDL\n")
        if reconstruct:
            subprocess.run("{} {}".format(run_pulchra, ca_file_path), shell=True, stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)

    # create many ca pdb files
    else:
        for coords, sequence, name in zip(ca_coords, sequences, names):
            ca_file_name = "{}_nanonet_ca.pdb".format(name)
            ca_file_path = os.path.join(output_dir, ca_file_name)
            with open(ca_file_path, "w") as ca_file:
                ca_file.write(HEADER.format(name))
                matrix_to_pdb(ca_file, sequence, coords, name)
            if reconstruct:
                subprocess.run("{} {}".format(run_pulchra, ca_file_path), shell=True, stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)



if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument("fasta", help="fasta file with Nbs sequences")
    parser.add_argument("-n", "--nanonet", help="path to NanoNet trained network (default: NanoNet)", type=str)
    parser.add_argument("-s", "--single_file", help="write all the models into a single PDB file with different models (good when predicting many structures, default: False)", action="store_true")
    parser.add_argument("-o", "--output_dir", help="directory to put the predicted PDB models, (default: ./NanoNetResults)", type=str)
    parser.add_argument("-r", "--reconstruct", help="reconstruct the side chains using pulchra, (default: False)", action="store_true")
    parser.add_argument("-p", "--pulchra", help="path to pulchra executable, in order to reconstruct the side chains, (default: ./pulchra_306/pulchra)", type=str)
    args = parser.parse_args()

    # check arguments
    fasta_path = args.fasta
    nanonet_path = args.nanonet if args.nanonet else "NanoNet"
    output_dir = args.output_dir if args.output_dir else os.path.join(".","NanoNetResults")
    run_pulchra = args.pulchra if args.pulchra else os.path.join("pulchra_306","pulchra")

    if not os.path.exists(fasta_path):
        print("Fasta file '{}' does not exist, aborting.".format(args.fasta), file=sys.stderr)
        exit(1)
    if not os.path.exists(nanonet_path):
        print("Trained NanoNet '{}' does not exist, aborting.".format(args.nanonet), file=sys.stderr)
        exit(1)
           
    start = timer()
    run_nanonet(fasta_path, nanonet_path, args.single_file, output_dir, args.reconstruct, run_pulchra)
    end = timer()

    print("NanoNet ended successfully, models are located in directory:'{}', total time : {}.".format(output_dir, end - start))
